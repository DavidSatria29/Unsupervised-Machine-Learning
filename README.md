# Uncovering the True Grades of Banana Quality: A Clustering Approach

## üìù Overview

This project explores the banana quality dataset using unsupervised machine learning techniques. The primary goal is to move beyond a simple binary "Good" or "Bad" classification by applying various clustering algorithms to identify natural groupings based on the bananas' physical and chemical attributes.

The analysis compares three popular clustering methods‚ÄîK-Means, Agglomerative Hierarchical Clustering, and DBSCAN‚Äîto determine which approach best reveals the underlying structure of the data. The final evaluation provides insights into the optimal number of quality grades and recommends a model that is both statistically sound and relevant to a business context.

***

## üìä Dataset

The analysis is performed on the **`banana_quality.csv`** dataset.

* **Features:** The dataset includes seven numerical features that describe the properties of each banana:
    * `Size`
    * `Weight`
    * `Sweetness`
    * `Softness`
    * `HarvestTime`
    * `Ripeness`
    * `Acidity`
* **Labels (for Evaluation):** An eighth column, `Quality`, provides original labels of "Good" or "Bad". This label is **not used** for training the models but serves as a benchmark for external validation.

***

## üõ†Ô∏è Methodology

The project follows a systematic approach to unsupervised learning:

1.  **Data Preprocessing:**
    * The dataset was first checked and confirmed to be clean, with **no missing values or duplicates**.
    * All numerical features were **standardized using `StandardScaler`** to ensure that each feature contributes equally to the distance-based calculations of the clustering algorithms.

2.  **Clustering Algorithms Implemented:**
    * **K-Means Clustering:** An iterative algorithm that partitions the data into a pre-defined number of clusters (`k`). The optimal `k` was determined using the Silhouette Score.
    * **Agglomerative Hierarchical Clustering:** A bottom-up approach that builds a hierarchy of clusters. The optimal `k` was also determined using the Silhouette Score.
    * **DBSCAN:** A density-based algorithm that groups together closely packed points. Parameters were tuned using a K-distance plot.

3.  **Model Evaluation:**
    * **Cluster Separability:** A Logistic Regression model was trained to predict the cluster labels generated by each algorithm. A high accuracy indicates that the clusters are well-defined and linearly separable.
    * **External Validation:** The Adjusted Rand Index (ARI) and Adjusted Mutual Information (AMI) scores were used to compare the algorithm-generated clusters against the original `Quality` labels.

***

## üìà Key Findings & Conclusion

* **Optimal Number of Clusters is Four:** Both K-Means and Agglomerative Clustering independently identified **four** as the optimal number of clusters. This key insight suggests that banana quality is more nuanced than a simple binary classification.

* **Algorithm Performance:**
    * **K-Means** produced the most mathematically distinct clusters, demonstrating high separability (99.5% accuracy in the logistic regression test).
    * **Agglomerative Clustering** created clusters that showed the strongest alignment with the original "Good" vs. "Bad" labels, making its results more practically interpretable.
    * **DBSCAN** was found to be unsuitable for this dataset, as it identified only one large cluster.

* **Final Model Recommendation:**
    **Agglomerative Clustering** is the recommended final model. Although K-Means created more mathematically perfect clusters, the groups from Agglomerative Clustering align better with the real-world labels, making them more valuable and actionable for business applications like product grading.

***

## ‚öôÔ∏è Installation & Usage

To run this project on your local machine, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Install dependencies:**
    It is recommended to use a virtual environment. The project requires the following libraries, which can be installed via pip:
    ```bash
    pip install pandas numpy seaborn matplotlib scikit-learn kneed
    ```

3.  **Run the Notebook:**
    Launch Jupyter Notebook or JupyterLab and open the `Unsupervised_Machine_Learning.ipynb` file. The notebook is self-contained and will run the analysis from data loading to final evaluation.

***

## üöÄ Next Steps

To further enhance this analysis, the following steps are recommended:

* **Analyze Cluster Profiles:** Perform an in-depth analysis of the four clusters from the Agglomerative model. By examining the feature averages for each cluster, business-relevant profiles can be created (e.g., "Premium Sweet," "Standard," "For Processing").
* **Improve Visualization:** Use dimensionality reduction techniques like **PCA** or **t-SNE** to create more accurate 2D visualizations of the clusters.
* **Incorporate New Features:** Enhance the dataset with additional features, such as color metrics or origin information, to potentially discover even more meaningful clusters.
